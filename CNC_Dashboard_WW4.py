import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import requests
import re
import concurrent.futures
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import random

from google.oauth2 import service_account 
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    DateRange, Dimension, Metric, RunReportRequest, OrderBy
)

st.set_page_config(
    layout="wide", 
    page_title="Ïø°Ïï§ÏÖ∞ÌîÑ Ï£ºÍ∞Ñ ÏÑ±Í≥ºÎ≥¥Í≥†ÏÑú", 
    page_icon="üì∞", 
    initial_sidebar_state="collapsed"
)

COLOR_NAVY = "#1a237e"
COLOR_RED = "#d32f2f"
COLOR_GREY = "#78909c"
COLOR_BG_ACCENT = "#fffcf7"
CHART_PALETTE = [COLOR_NAVY, COLOR_RED, "#5c6bc0", "#ef5350", "#8d6e63", COLOR_GREY]
COLOR_GENDER = {'Ïó¨ÏÑ±': '#d32f2f', 'ÎÇ®ÏÑ±': '#1a237e'} 

CSS = f"""
<style>
@import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.8/dist/web/static/pretendard.css');
body {{ background-color: #ffffff; font-family: 'Pretendard', sans-serif; color: #263238; font-size: 16px; }}

header[data-testid="stHeader"] {{ visibility: hidden !important; }}
[data-testid="stToolbar"] {{ visibility: hidden !important; }}
.block-container {{ padding-top: 2rem !important; padding-bottom: 5rem; max_width: 1800px; }}
[data-testid="stSidebar"] {{ display: none; }}

.report-title {{ font-size: 3.2rem; font-weight: 900; color: {COLOR_NAVY}; border-bottom: 4px solid {COLOR_RED}; padding-bottom: 15px; margin-top: 10px; }}
.period-info {{ font-size: 1.4rem; font-weight: 700; color: #455a64; margin-top: 10px; }}
.update-time {{ color: {COLOR_NAVY}; font-weight: 700; font-size: 1.2rem; text-align: right; margin-top: -15px; margin-bottom: 30px; font-family: monospace; }}
.kpi-container {{ background-color: #fff; border: 1px solid #eceff1; border-top: 5px solid {COLOR_RED}; border-radius: 8px; padding: 25px 15px; text-align: center; margin-bottom: 15px; height: 180px; display: flex; flex-direction: column; justify-content: center; box-shadow: 0 4px 12px rgba(0,0,0,0.03); }}
.kpi-label {{ font-size: 1.3rem; font-weight: 700; color: #455a64; margin-bottom: 10px; white-space: nowrap; letter-spacing: -0.05em; }}
.kpi-value {{ font-size: 2.8rem; font-weight: 900; color: {COLOR_NAVY}; line-height: 1.1; letter-spacing: -0.03em; }}
.kpi-unit {{ font-size: 1.3rem; font-weight: 600; color: #90a4ae; margin-left: 3px; }}
.section-header-container {{ margin-top: 30px; margin-bottom: 25px; padding: 20px 30px; background-color: {COLOR_BG_ACCENT}; border-left: 8px solid {COLOR_NAVY}; border-radius: 4px; }}
.section-header {{ font-size: 2.2rem; font-weight: 800; color: {COLOR_NAVY}; margin: 0; }}
.section-desc {{ font-size: 1.2rem; color: #546e7a; margin-top: 5px; }}
.sub-header {{ font-size: 1.6rem; font-weight: 700; color: {COLOR_NAVY}; margin-top: 30px; margin-bottom: 10px; padding-left: 10px; border-left: 4px solid {COLOR_RED}; }}
.chart-header {{ font-size: 1.4rem; font-weight: 700; color: {COLOR_NAVY}; margin-top: 30px; margin-bottom: 10px; border-left: 4px solid {COLOR_RED}; padding-left: 10px; }}
.stTabs [data-baseweb="tab-list"] {{ gap: 0px; border-bottom: 2px solid #cfd8dc; display: flex; width: 100%; }}
.stTabs [data-baseweb="tab"] {{ height: 70px; background-color: #f7f9fa; border-right: 1px solid #eceff1; color: #607d8b; font-weight: 700; font-size: 1.3rem; flex-grow: 1; text-align: center; }}
.stTabs [aria-selected="true"] {{ background-color: #fff; color: {COLOR_RED}; border-bottom: 4px solid {COLOR_RED}; }}
[data-testid="stDataFrame"] thead th {{ background-color: {COLOR_NAVY} !important; color: white !important; font-size: 1.2rem !important; font-weight: 600 !important; }}
[data-testid="stDataFrame"] tbody td {{ font-size: 1.1rem !important; }}
.footer-note {{ font-size: 1rem; color: #78909c; margin-top: 50px; border-top: 1px solid #eceff1; padding-top: 15px; text-align: center; }}

.traffic-tooltip {{ background-color: rgba(26, 35, 126, 0.95); color: white; padding: 8px 12px; border-radius: 4px; font-size: 0.9rem; }}
.tooltip-container {{ position: relative; display: inline-block; }}
.tooltip-container:hover .traffic-tooltip {{ visibility: visible; opacity: 1; }}
.traffic-tooltip {{ visibility: hidden; opacity: 0; position: absolute; z-index: 1; bottom: 125%; left: 50%; margin-left: -60px; transition: opacity 0.3s; }}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)

PRINT_CSS = """
<style>
.print-preview-layout {
    transform: scale(0.9); 
    transform-origin: top center; 
    width: 111%;
}

@media print {
    @page { 
        size: A4 landscape; 
        margin: 8mm; 
    }
    
    body { 
        transform: scale(0.85) !important; 
        transform-origin: top left !important; 
        width: 118% !important;
        font-size: 18px !important;
    }
    
    .no-print, .stButton, header, footer, [data-testid="stSidebar"] { display: none !important; }
    
    .page-break { 
        page-break-before: always !important; 
        break-before: page !important;
        display: block;
        height: 1px;
        margin-top: 20px;
    }
    
    [data-testid="stDataFrame"] {
        width: 100% !important;
        font-size: 14px !important;
    }
    [data-testid="stDataFrame"] > div {
        width: 100% !important;
    }
    
    .section-header-container { margin-top: 8px !important; }
    .block-container { padding-top: 0 !important; }
    
    .print-footer {
        position: fixed;
        bottom: 0;
        width: 100%;
        text-align: center;
        font-size: 12px;
        color: #999;
    }
    
    .kpi-container { height: 140px !important; }
    .section-header { font-size: 1.8rem !important; }
    .sub-header { font-size: 1.4rem !important; }
}
</style>
"""
st.markdown(PRINT_CSS, unsafe_allow_html=True)

def check_password():
    if st.session_state.get("password_correct", False):
        return True

    login_placeholder = st.empty()
    with login_placeholder.container():
        st.markdown(
            """
            <style>
            .login-container { max-width: 400px; margin: 100px auto; padding: 40px; text-align: center; }
            .login-title { font-size: 28px; font-weight: 700; color: #1a237e; margin-bottom: 20px; text-align: center; }
            .powered-by { font-size: 14px; color: #90a4ae; margin-top: 50px; font-weight: 500; }
            .stTextInput > div > div > input { text-align: center; font-size: 20px; letter-spacing: 2px; }
            </style>
            """, unsafe_allow_html=True
        )
        c1, c2, c3 = st.columns([1, 2, 1])
        with c2:
            st.markdown('<div style="margin-top: 100px;"></div>', unsafe_allow_html=True)
            st.markdown('<div class="login-title">üîí Ïø°Ïï§ÏÖ∞ÌîÑ Ï£ºÍ∞Ñ ÏÑ±Í≥ºÎ≥¥Í≥†ÏÑú</div>', unsafe_allow_html=True)
            password = st.text_input("Access Code", type="password", key="password_input", label_visibility="collapsed")
            if password:
                if password == "cncnews2026":
                    st.session_state["password_correct"] = True
                    login_placeholder.empty()
                    st.rerun()
                else:
                    st.error("üö´ ÏΩîÎìúÍ∞Ä Ïò¨Î∞îÎ•¥ÏßÄ ÏïäÏäµÎãàÎã§.")
            
            st.markdown('<div class="powered-by">Powered by DWG Inc.</div>', unsafe_allow_html=True)
            
    return False

if not check_password():
    st.stop()

PROPERTY_ID = "370663478" 

@st.cache_resource
def get_ga4_client():
    try:
        key_dict = st.secrets["ga4_credentials"]
        creds = service_account.Credentials.from_service_account_info(key_dict)
        return BetaAnalyticsDataClient(credentials=creds)
    except Exception as e:
        st.error(f"GA4 ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ïó∞Í≤∞ Ïã§Ìå®: {e}")
        return None

def clean_author_name(name):
    if not name: return "ÎØ∏ÏÉÅ"
    name = name.replace('#', '').replace('Í∏∞Ïûê', '')
    return ' '.join(name.split())

def get_publish_date_from_path(url_path):
    try:
        date_match = re.search(r'/(\d{4})/(\d{1,2})/(\d{1,2})/', url_path)
        if date_match:
            year, month, day = date_match.groups()
            return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        
        return (datetime.now() - timedelta(days=random.randint(1, 7))).strftime('%Y-%m-%d')
    except:
        return datetime.now().strftime('%Y-%m-%d')

def crawl_single_article(url_path):
    full_url = f"http://www.cooknchefnews.com{url_path}"
    try:
        response = requests.get(full_url, timeout=2)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        author = "Í¥ÄÎ¶¨Ïûê"
        author_tag = soup.select_one('.user-name') or soup.select_one('.writer') or soup.select_one('.byline')
        if author_tag: author = author_tag.text.strip()
        else:
            for tag in soup.select('span, div, li'):
                txt = tag.text.strip()
                if 'Í∏∞Ïûê' in txt and len(txt) < 10:
                    author = txt; break
        author = clean_author_name(author)
        
        publish_date = get_publish_date_from_path(url_path)
        date_tag = soup.select_one('.date') or soup.select_one('.publish-date') or soup.select_one('time')
        if date_tag:
            date_text = date_tag.text.strip()
            try:
                parsed_date = pd.to_datetime(date_text)
                publish_date = parsed_date.strftime('%Y-%m-%d')
            except:
                pass
        
        likes = int(soup.select_one('.sns-like-count').text.replace(',', '')) if soup.select_one('.sns-like-count') else 0
        comments = int(soup.select_one('.comment-count').text.replace(',', '')) if soup.select_one('.comment-count') else 0
        
        cat, subcat = "Îâ¥Ïä§", "Ïù¥Ïäà"
        breadcrumbs = soup.select('.location a') or soup.select('.breadcrumb a') or soup.select('.path a')
        if breadcrumbs:
            if len(breadcrumbs) >= 2: cat = breadcrumbs[1].text.strip()
            if len(breadcrumbs) >= 3: subcat = breadcrumbs[2].text.strip()
        else:
            meta_sec = soup.select_one('meta[property="article:section"]')
            if meta_sec: cat = meta_sec.get('content')
        
        return (author, likes, comments, cat, subcat, publish_date)
    except: 
        return ("Í¥ÄÎ¶¨Ïûê", 0, 0, "Îâ¥Ïä§", "Ïù¥Ïäà", datetime.now().strftime('%Y-%m-%d'))

def get_sunday_to_saturday_ranges(count=12):
    ranges = {}
    today = datetime.now()
    days_since_sunday = (today.weekday() + 1) % 7
    last_sunday = today - timedelta(days=days_since_sunday)
    for i in range(count):
        start_date = last_sunday - timedelta(weeks=i)
        end_date = start_date + timedelta(days=6)
        label = f"{start_date.isocalendar()[1]}Ï£ºÏ∞®"
        ranges[label] = f"{start_date.strftime('%Y.%m.%d')} ~ {end_date.strftime('%Y.%m.%d')}"
    return ranges
WEEK_MAP = get_sunday_to_saturday_ranges()

def run_ga4_report(start_date, end_date, dimensions, metrics, order_by_metric=None, limit=None):
    client = get_ga4_client()
    if not client: return pd.DataFrame()
    order_bys = [OrderBy(metric=OrderBy.MetricOrderBy(metric_name=order_by_metric), desc=True)] if order_by_metric else []
    request = RunReportRequest(
        property=f"properties/{PROPERTY_ID}",
        dimensions=[Dimension(name=d) for d in dimensions],
        metrics=[Metric(name=m) for m in metrics],
        date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
        order_bys=order_bys,
        limit=limit if limit else 10000
    )
    try:
        response = client.run_report(request)
        data = []
        for row in response.rows:
            row_dict = {dimensions[i]: row.dimension_values[i].value for i in range(len(dimensions))}
            for i, met in enumerate(metrics):
                val = row.metric_values[i].value
                row_dict[met] = float(val) if '.' in val else int(val)
            data.append(row_dict)
        return pd.DataFrame(data)
    except: 
        return pd.DataFrame(columns=dimensions + metrics)

def get_article_traffic_sources(start_date, end_date, page_paths):
    client = get_ga4_client()
    if not client or not page_paths: return pd.DataFrame()
    
    article_traffic = []
    
    for path in page_paths[:20]: 
        traffic_data = run_ga4_report(start_date, end_date, 
                                    ["pagePath", "sessionSource"], 
                                    ["screenPageViews"], 
                                    limit=1000)
        
        if not traffic_data.empty:
            path_data = traffic_data[traffic_data['pagePath'] == path]
            if not path_data.empty:
                for _, row in path_data.iterrows():
                    source_mapped = map_traffic_source(row['sessionSource'])
                    article_traffic.append({
                        'pagePath': path,
                        'Ïú†ÏûÖÍ≤ΩÎ°ú': source_mapped,
                        'Ï°∞ÌöåÏàò': row['screenPageViews']
                    })
    
    return pd.DataFrame(article_traffic)

def map_traffic_source(source):
    source = source.lower()
    if 'naver' in source: return 'ÎÑ§Ïù¥Î≤Ñ'
    if 'daum' in source: return 'Îã§Ïùå'
    if 'facebook' in source: return 'ÌéòÏù¥Ïä§Î∂Å'
    if '(direct)' in source: return 'ÏßÅÏ†ë Ï†ëÍ∑º'
    if 'google' in source: return 'Íµ¨Í∏Ä'
    if 'youtube' in source: return 'Ïú†ÌäúÎ∏å'
    if 'instagram' in source: return 'Ïù∏Ïä§ÌÉÄÍ∑∏Îû®'
    if 'twitter' in source: return 'Ìä∏ÏúÑÌÑ∞'
    if 'kakao' in source: return 'Ïπ¥Ïπ¥Ïò§'
    return 'Í∏∞ÌÉÄ'

def create_donut_chart_with_val(df, names, values, color_map=None, size='normal'):
    if df.empty: return go.Figure()
    
    if size == 'small':
        height, margin_dict = 250, dict(t=15, b=50, l=25, r=25)
    else:
        height, margin_dict = 350, dict(t=30, b=80, l=40, r=40)
    
    if 'Íµ¨Î∂Ñ' in df.columns:
        df_normal = df[df['Íµ¨Î∂Ñ'] != 'Í∏∞ÌÉÄ'].sort_values(by=values, ascending=False)
        df_other = df[df['Íµ¨Î∂Ñ'] == 'Í∏∞ÌÉÄ']
        df_sorted = pd.concat([df_normal, df_other])
    else: df_sorted = df
    
    if color_map: 
        fig = px.pie(df_sorted, names=names, values=values, hole=0.5, color=names, color_discrete_map=color_map)
    else: 
        fig = px.pie(df_sorted, names=names, values=values, hole=0.5, color_discrete_sequence=CHART_PALETTE)
    
    fig.update_traces(textposition='outside', textinfo='label+percent', sort=False)
    fig.update_layout(showlegend=False, margin=margin_dict, height=height)
    
    return fig

def evaluate_freelancer_performance(writers_df, df_all_articles):
    if writers_df.empty: return pd.DataFrame()
    
    freelancers = ['ÎßõÍ∞ù', 'Ïù¥Í≤ΩÏóΩ', 'Chef J', 'Ï°∞Ïö©Ïàò', 'Ìë∏ÎìúÌóåÌÑ∞', 'ÍπÄÏ≤†Ìò∏', 'Dr.Kim', 'ÏïàÏ†ïÎØ∏']
    
    freelancer_data = []
    for _, writer in writers_df.iterrows():
        if any(fl in writer['ÏûëÏÑ±Ïûê'] for fl in freelancers):
            avg_views = writer['ÌèâÍ∑†Ï°∞ÌöåÏàò']
            total_articles = writer['Í∏∞ÏÇ¨Ïàò']
            engagement_score = (writer['Ï¢ãÏïÑÏöî'] + writer['ÎåìÍ∏Ä'] * 2) / total_articles if total_articles > 0 else 0
            
            if avg_views >= 1000: grade = 'S'
            elif avg_views >= 700: grade = 'A'
            elif avg_views >= 500: grade = 'B'
            elif avg_views >= 300: grade = 'C'
            else: grade = 'D'
            
            freelancer_data.append({
                'Í∏∞ÏûêÎ™Ö': writer['ÏûëÏÑ±Ïûê'],
                'Î∞úÌñâÍ∏∞ÏÇ¨Ïàò': total_articles,
                'ÌèâÍ∑†Ï°∞ÌöåÏàò': avg_views,
                'Ï∞∏Ïó¨ÎèÑÏ†êÏàò': round(engagement_score, 1),
                'ÏÑ±Í≥ºÎì±Í∏â': grade,
                'Ï¥ùÏ°∞ÌöåÏàò': writer['Ï¥ùÏ°∞ÌöåÏàò']
            })
    
    return pd.DataFrame(freelancer_data).sort_values('ÌèâÍ∑†Ï°∞ÌöåÏàò', ascending=False)

@st.cache_data(ttl=3600, show_spinner="Îç∞Ïù¥ÌÑ∞ Î∂àÎü¨Ïò§Îäî Ï§ë...")
def load_all_dashboard_data(selected_week):
    dr = WEEK_MAP[selected_week]
    s_dt, e_dt = dr.split(' ~ ')[0].replace('.', '-'), dr.split(' ~ ')[1].replace('.', '-')
    ls_dt = (datetime.strptime(s_dt, '%Y-%m-%d')-timedelta(days=7)).strftime('%Y-%m-%d')
    le_dt = (datetime.strptime(e_dt, '%Y-%m-%d')-timedelta(days=7)).strftime('%Y-%m-%d')

    # KPI
    summary = run_ga4_report(s_dt, e_dt, [], ["activeUsers", "screenPageViews", "newUsers"])
    if not summary.empty:
        sel_uv = int(summary['activeUsers'].iloc[0])
        sel_pv = int(summary['screenPageViews'].iloc[0])
        sel_new = int(summary['newUsers'].iloc[0])
    else: sel_uv, sel_pv, sel_new = 0, 0, 0
    new_visitor_ratio = round((sel_new / sel_uv * 100), 1) if sel_uv > 0 else 0

    # ÏùºÎ≥Ñ Îç∞Ïù¥ÌÑ∞
    df_daily = run_ga4_report(s_dt, e_dt, ["date"], ["activeUsers", "screenPageViews"])
    if not df_daily.empty:
        df_daily = df_daily.rename(columns={'date':'ÎÇ†Ïßú', 'activeUsers':'UV', 'screenPageViews':'PV'})
        df_daily['ÎÇ†Ïßú'] = pd.to_datetime(df_daily['ÎÇ†Ïßú']).dt.strftime('%m-%d')
    
    # 3Í∞úÏõî Ï∂îÏù¥
    def fetch_week_data(week_label, date_str):
        ws, we = date_str.split(' ~ ')[0].replace('.', '-'), date_str.split(' ~ ')[1].replace('.', '-')
        res = run_ga4_report(ws, we, [], ["activeUsers", "screenPageViews"])
        if not res.empty:
            return {
                'Ï£ºÏ∞®': week_label, 
                'UV': int(res['activeUsers'][0]), 
                'PV': int(res['screenPageViews'][0])
            }
        return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(fetch_week_data, wl, dstr) for wl, dstr in list(WEEK_MAP.items())[:12]]
        results = [f.result() for f in concurrent.futures.as_completed(futures) if f.result()]
    
    df_weekly = pd.DataFrame(results)
    if not df_weekly.empty:
        df_weekly['week_num'] = df_weekly['Ï£ºÏ∞®'].apply(lambda x: int(re.search(r'\d+', x).group()))
        df_weekly = df_weekly.sort_values('week_num')
    
    # ÌôúÏÑ± Í∏∞ÏÇ¨ Ïàò
    df_pages_count = run_ga4_report(s_dt, e_dt, ["pagePath"], ["screenPageViews"], limit=10000)
    if not df_pages_count.empty:
        mask_article = df_pages_count['pagePath'].str.contains(r'article|news|view|story', case=False, regex=True, na=False)
        active_article_count = df_pages_count[mask_article].shape[0]
        if active_article_count == 0:
             active_article_count = df_pages_count[df_pages_count['pagePath'].str.len() > 1].shape[0]
    else:
        active_article_count = 0

    # Ïú†ÏûÖÍ≤ΩÎ°ú
    df_t_raw = run_ga4_report(s_dt, e_dt, ["sessionSource"], ["screenPageViews"])
    df_t_raw['Ïú†ÏûÖÍ≤ΩÎ°ú'] = df_t_raw['sessionSource'].apply(map_traffic_source)
    df_traffic_curr = df_t_raw.groupby('Ïú†ÏûÖÍ≤ΩÎ°ú')['screenPageViews'].sum().reset_index().rename(columns={'screenPageViews':'Ï°∞ÌöåÏàò'})
    
    search_engines = ['ÎÑ§Ïù¥Î≤Ñ', 'Íµ¨Í∏Ä', 'Îã§Ïùå']
    search_pv = df_traffic_curr[df_traffic_curr['Ïú†ÏûÖÍ≤ΩÎ°ú'].isin(search_engines)]['Ï°∞ÌöåÏàò'].sum()
    total_pv_traffic = df_traffic_curr['Ï°∞ÌöåÏàò'].sum()
    search_inflow_ratio = round((search_pv / total_pv_traffic * 100), 1) if total_pv_traffic > 0 else 0
    
    df_tl_raw = run_ga4_report(ls_dt, le_dt, ["sessionSource"], ["screenPageViews"])
    df_tl_raw['Ïú†ÏûÖÍ≤ΩÎ°ú'] = df_tl_raw['sessionSource'].apply(map_traffic_source)
    df_traffic_last = df_tl_raw.groupby('Ïú†ÏûÖÍ≤ΩÎ°ú')['screenPageViews'].sum().reset_index().rename(columns={'screenPageViews':'Ï°∞ÌöåÏàò'})

    # Î∞©Î¨∏Ïûê ÌäπÏÑ±
    def clean_and_group(df, col_name):
        if df.empty: return pd.DataFrame(columns=['Íµ¨Î∂Ñ', 'activeUsers'])
        df['Íµ¨Î∂Ñ'] = df[col_name].replace({'(not set)': 'Í∏∞ÌÉÄ', '': 'Í∏∞ÌÉÄ', 'unknown': 'Í∏∞ÌÉÄ'}).fillna('Í∏∞ÌÉÄ')
        return df.groupby('Íµ¨Î∂Ñ', as_index=False)['activeUsers'].sum()

    region_map = {'Seoul':'ÏÑúÏö∏','Gyeonggi-do':'Í≤ΩÍ∏∞','Incheon':'Ïù∏Ï≤ú','Busan':'Î∂ÄÏÇ∞','Daegu':'ÎåÄÍµ¨','Gyeongsangnam-do':'Í≤ΩÎÇ®','Gyeongsangbuk-do':'Í≤ΩÎ∂Å','Chungcheongnam-do':'Ï∂©ÎÇ®','Chungcheongbuk-do':'Ï∂©Î∂Å','Jeollanam-do':'Ï†ÑÎÇ®','Jeollabuk-do':'Ï†ÑÎ∂Å','Gangwon-do':'Í∞ïÏõê','Daejeon':'ÎåÄÏ†Ñ','Gwangju':'Í¥ëÏ£º','Ulsan':'Ïö∏ÏÇ∞','Jeju-do':'Ï†úÏ£º','Sejong-si':'ÏÑ∏Ï¢Ö'}
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
        f_reg_c = executor.submit(run_ga4_report, s_dt, e_dt, ["region"], ["activeUsers"], "activeUsers", 50)
        f_reg_l = executor.submit(run_ga4_report, ls_dt, le_dt, ["region"], ["activeUsers"], "activeUsers", 50)
        f_age_c = executor.submit(run_ga4_report, s_dt, e_dt, ["userAgeBracket"], ["activeUsers"], "activeUsers")
        f_age_l = executor.submit(run_ga4_report, ls_dt, le_dt, ["userAgeBracket"], ["activeUsers"], "activeUsers")
        f_gen_c = executor.submit(run_ga4_report, s_dt, e_dt, ["userGender"], ["activeUsers"], "activeUsers")
        f_gen_l = executor.submit(run_ga4_report, ls_dt, le_dt, ["userGender"], ["activeUsers"], "activeUsers")

        d_rc, d_rl = f_reg_c.result(), f_reg_l.result()
        if not d_rc.empty: d_rc['region_mapped'] = d_rc['region'].map(region_map).fillna('Í∏∞ÌÉÄ')
        if not d_rl.empty: d_rl['region_mapped'] = d_rl['region'].map(region_map).fillna('Í∏∞ÌÉÄ')
        df_region_curr = clean_and_group(d_rc, 'region_mapped')
        df_region_last = clean_and_group(d_rl, 'region_mapped')

        d_ac, d_al = f_age_c.result(), f_age_l.result()
        for df in [d_ac, d_al]:
            if not df.empty:
                df['temp_age'] = df['userAgeBracket'].replace({'unknown': 'Í∏∞ÌÉÄ', '(not set)': 'Í∏∞ÌÉÄ'})
                df['Íµ¨Î∂Ñ'] = df['temp_age'].apply(lambda x: x + 'ÏÑ∏' if x != 'Í∏∞ÌÉÄ' else x)
        df_age_curr = d_ac[d_ac['Íµ¨Î∂Ñ'] != 'Í∏∞ÌÉÄ'].groupby('Íµ¨Î∂Ñ', as_index=False)['activeUsers'].sum() if not d_ac.empty else pd.DataFrame()
        df_age_last = d_al[d_al['Íµ¨Î∂Ñ'] != 'Í∏∞ÌÉÄ'].groupby('Íµ¨Î∂Ñ', as_index=False)['activeUsers'].sum() if not d_al.empty else pd.DataFrame()

        d_gc, d_gl = f_gen_c.result(), f_gen_l.result()
        gender_map = {'male': 'ÎÇ®ÏÑ±', 'female': 'Ïó¨ÏÑ±'}
        for df in [d_gc, d_gl]:
            if not df.empty:
                df['mapped'] = df['userGender'].map(gender_map)
                df['Íµ¨Î∂Ñ'] = df['mapped']
        df_gender_curr = d_gc.dropna(subset=['mapped']).groupby('Íµ¨Î∂Ñ', as_index=False)['activeUsers'].sum() if not d_gc.empty else pd.DataFrame()
        df_gender_last = d_gl.dropna(subset=['mapped']).groupby('Íµ¨Î∂Ñ', as_index=False)['activeUsers'].sum() if not d_gl.empty else pd.DataFrame()

    # TOP 10 ÌÅ¨Î°§ÎßÅ
    df_raw_top = run_ga4_report(s

