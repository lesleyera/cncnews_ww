import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
import requests
import re
import concurrent.futures
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import random

# ì¸ì¦ ëª¨ë“ˆ
from google.oauth2 import service_account 
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    DateRange, Dimension, Metric, RunReportRequest, OrderBy
)

# ----------------- 1. í˜ì´ì§€ ì„¤ì • -----------------
st.set_page_config(
    layout="wide", 
    page_title="ì¿¡ì•¤ì…°í”„ ì£¼ê°„ ì„±ê³¼ë³´ê³ ì„œ", 
    page_icon="ğŸ“°", 
    initial_sidebar_state="collapsed"
)

# ----------------- 2. CSS ìŠ¤íƒ€ì¼ ì •ì˜ (ê¸°ë³¸ + ì¸ì‡„) -----------------
COLOR_NAVY = "#1a237e"
COLOR_RED = "#d32f2f"
COLOR_GREY = "#78909c"
COLOR_BG_ACCENT = "#fffcf7"
CHART_PALETTE = [COLOR_NAVY, COLOR_RED, "#5c6bc0", "#ef5350", "#8d6e63", COLOR_GREY]
COLOR_GENDER = {'ì—¬ì„±': '#d32f2f', 'ë‚¨ì„±': '#1a237e'} 

# ê¸°ë³¸ í™”ë©´ ìŠ¤íƒ€ì¼
CSS = f"""
<style>
@import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.8/dist/web/static/pretendard.css');
body {{ background-color: #ffffff; font-family: 'Pretendard', sans-serif; color: #263238; }}

/* í—¤ë” ë° íˆ´ë°” ìˆ¨ê¹€ */
header[data-testid="stHeader"] {{ visibility: hidden !important; }}
[data-testid="stToolbar"] {{ visibility: hidden !important; }}
.block-container {{ padding-top: 2rem !important; padding-bottom: 5rem; max_width: 1600px; }}
[data-testid="stSidebar"] {{ display: none; }}

/* ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ */
.report-title {{ font-size: 2.6rem; font-weight: 900; color: {COLOR_NAVY}; border-bottom: 4px solid {COLOR_RED}; padding-bottom: 15px; margin-top: 10px; }}
.period-info {{ font-size: 1.2rem; font-weight: 700; color: #455a64; margin-top: 10px; }}
.update-time {{ color: {COLOR_NAVY}; font-weight: 700; font-size: 1.1rem; text-align: right; margin-top: -15px; margin-bottom: 30px; font-family: monospace; }}
.kpi-container {{ background-color: #fff; border: 1px solid #eceff1; border-top: 5px solid {COLOR_RED}; border-radius: 8px; padding: 20px 10px; text-align: center; margin-bottom: 15px; height: 160px; display: flex; flex-direction: column; justify-content: center; box-shadow: 0 4px 12px rgba(0,0,0,0.03); }}
.kpi-label {{ font-size: 1.1rem; font-weight: 700; color: #455a64; margin-bottom: 10px; white-space: nowrap; letter-spacing: -0.05em; }}
.kpi-value {{ font-size: 2.4rem; font-weight: 900; color: {COLOR_NAVY}; line-height: 1.1; letter-spacing: -0.03em; }}
.kpi-unit {{ font-size: 1.1rem; font-weight: 600; color: #90a4ae; margin-left: 3px; }}
.section-header-container {{ margin-top: 30px; margin-bottom: 25px; padding: 15px 25px; background-color: {COLOR_BG_ACCENT}; border-left: 8px solid {COLOR_NAVY}; border-radius: 4px; }}
.section-header {{ font-size: 1.8rem; font-weight: 800; color: {COLOR_NAVY}; margin: 0; }}
.section-desc {{ font-size: 1rem; color: #546e7a; margin-top: 5px; }}
.sub-header {{ font-size: 1.3rem; font-weight: 700; color: {COLOR_NAVY}; margin-top: 30px; margin-bottom: 10px; padding-left: 10px; border-left: 4px solid {COLOR_RED}; }}
.chart-header {{ font-size: 1.2rem; font-weight: 700; color: {COLOR_NAVY}; margin-top: 30px; margin-bottom: 10px; border-left: 4px solid {COLOR_RED}; padding-left: 10px; }}
.stTabs [data-baseweb="tab-list"] {{ gap: 0px; border-bottom: 2px solid #cfd8dc; display: flex; width: 100%; }}
.stTabs [data-baseweb="tab"] {{ height: 60px; background-color: #f7f9fa; border-right: 1px solid #eceff1; color: #607d8b; font-weight: 700; font-size: 1.1rem; flex-grow: 1; text-align: center; }}
.stTabs [aria-selected="true"] {{ background-color: #fff; color: {COLOR_RED}; border-bottom: 4px solid {COLOR_RED}; }}
[data-testid="stDataFrame"] thead th {{ background-color: {COLOR_NAVY} !important; color: white !important; font-size: 1rem !important; font-weight: 600 !important; }}
.footer-note {{ font-size: 0.85rem; color: #78909c; margin-top: 50px; border-top: 1px solid #eceff1; padding-top: 15px; text-align: center; }}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)

# ----------------- ì¸ì‡„ ëª¨ë“œ ì „ìš© ìŠ¤íƒ€ì¼ -----------------
PRINT_CSS = """
<style>
.print-preview-layout { transform: scale(0.85); transform-origin: top center; width: 117%; }
@media print {
    @page { size: A4; margin: 10mm; }
    body { transform: scale(0.8) !important; transform-origin: top left !important; width: 125% !important; }
    .no-print, .stButton, header, footer, [data-testid="stSidebar"] { display: none !important; }
    .page-break { page-break-before: always !important; break-before: page !important; display: block; height: 1px; margin-top: 20px; }
    [data-testid="stDataFrame"] { width: 100% !important; }
    [data-testid="stDataFrame"] > div { width: 100% !important; }
    .section-header-container { margin-top: 10px !important; }
    .block-container { padding-top: 0 !important; }
    .print-footer { position: fixed; bottom: 0; width: 100%; text-align: center; font-size: 10px; color: #999; }
}
</style>
"""
st.markdown(PRINT_CSS, unsafe_allow_html=True)

# ----------------- 3. ì§„ì… ë³´ì•ˆ í™”ë©´ -----------------
def check_password():
    if st.session_state.get("password_correct", False): return True
    login_placeholder = st.empty()
    with login_placeholder.container():
        st.markdown("""
            <style>
            .login-container { max-width: 400px; margin: 100px auto; padding: 40px; text-align: center; }
            .login-title { font-size: 24px; font-weight: 700; color: #1a237e; margin-bottom: 20px; text-align: center; }
            .powered-by { font-size: 12px; color: #90a4ae; margin-top: 50px; font-weight: 500; }
            .stTextInput > div > div > input { text-align: center; font-size: 18px; letter-spacing: 2px; }
            </style>
            """, unsafe_allow_html=True)
        c1, c2, c3 = st.columns([1, 2, 1])
        with c2:
            st.markdown('<div style="margin-top: 100px;"></div>', unsafe_allow_html=True)
            st.markdown('<div class="login-title">ğŸ”’ ì¿¡ì•¤ì…°í”„ ì£¼ê°„ ì„±ê³¼ë³´ê³ ì„œ</div>', unsafe_allow_html=True)
            password = st.text_input("Access Code", type="password", key="password_input", label_visibility="collapsed")
            if password:
                if password == "cncnews2026":
                    st.session_state["password_correct"] = True
                    login_placeholder.empty()
                    st.rerun()
                else: st.error("ğŸš« ì½”ë“œê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.markdown('<div class="powered-by">Powered by DWG Inc.</div>', unsafe_allow_html=True)
    return False

if not check_password(): st.stop()

# ----------------- 4. GA4 ì„¤ì • ë° í¬ë¡¤ë§ -----------------
PROPERTY_ID = "370663478" 

@st.cache_resource
def get_ga4_client():
    try:
        key_dict = st.secrets["ga4_credentials"]
        creds = service_account.Credentials.from_service_account_info(key_dict)
        return BetaAnalyticsDataClient(credentials=creds)
    except Exception as e:
        st.error(f"GA4 í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def clean_author_name(name):
    if not name: return "ë¯¸ìƒ"
    name = name.replace('#', '').replace('ê¸°ì', '')
    return ' '.join(name.split())

def crawl_single_article(url_path):
    full_url = f"http://www.cooknchefnews.com{url_path}"
    try:
        response = requests.get(full_url, timeout=2)
        soup = BeautifulSoup(response.text, 'html.parser')
        author = "ê´€ë¦¬ì"
        author_tag = soup.select_one('.user-name') or soup.select_one('.writer') or soup.select_one('.byline')
        if author_tag: author = author_tag.text.strip()
        author = clean_author_name(author)
        likes = int(soup.select_one('.sns-like-count').text.replace(',', '')) if soup.select_one('.sns-like-count') else 0
        comments = int(soup.select_one('.comment-count').text.replace(',', '')) if soup.select_one('.comment-count') else 0
        cat, subcat = "ë‰´ìŠ¤", "ì´ìŠˆ"
        breadcrumbs = soup.select('.location a')
        if len(breadcrumbs) >= 2: cat = breadcrumbs[1].text.strip()
        if len(breadcrumbs) >= 3: subcat = breadcrumbs[2].text.strip()
        return (author, likes, comments, cat, subcat)
    except: return ("ê´€ë¦¬ì", 0, 0, "ë‰´ìŠ¤", "ì´ìŠˆ")

def get_sunday_to_saturday_ranges(count=12):
    ranges = {}
    today = datetime.now()
    days_since_sunday = (today.weekday() + 1) % 7
    last_sunday = today - timedelta(days=days_since_sunday)
    for i in range(count):
        start_date = last_sunday - timedelta(weeks=i)
        end_date = start_date + timedelta(days=6)
        label = f"{start_date.isocalendar()[1]}ì£¼ì°¨"
        ranges[label] = f"{start_date.strftime('%Y.%m.%d')} ~ {end_date.strftime('%Y.%m.%d')}"
    return ranges
WEEK_MAP = get_sunday_to_saturday_ranges()

def run_ga4_report(start_date, end_date, dimensions, metrics, order_by_metric=None, limit=None):
    client = get_ga4_client()
    if not client: return pd.DataFrame()
    order_bys = [OrderBy(metric=OrderBy.MetricOrderBy(metric_name=order_by_metric), desc=True)] if order_by_metric else []
    request = RunReportRequest(
        property=f"properties/{PROPERTY_ID}",
        dimensions=[Dimension(name=d) for d in dimensions],
        metrics=[Metric(name=m) for m in metrics],
        date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
        order_bys=order_bys,
        limit=limit if limit else 10000
    )
    try:
        response = client.run_report(request)
        data = []
        for row in response.rows:
            row_dict = {dimensions[i]: row.dimension_values[i].value for i in range(len(dimensions))}
            for i, met in enumerate(metrics):
                val = row.metric_values[i].value
                row_dict[met] = float(val) if '.' in val else int(val)
            data.append(row_dict)
        return pd.DataFrame(data)
    except: return pd.DataFrame()

# ----------------- 5. ë°ì´í„° ë¡œë”© (ìˆ˜ì • ë°˜ì˜) -----------------
@st.cache_data(ttl=3600)
def load_all_dashboard_data(selected_week):
    dr = WEEK_MAP[selected_week]
    s_dt, e_dt = dr.split(' ~ ')[0].replace('.', '-'), dr.split(' ~ ')[1].replace('.', '-')
    ls_dt = (datetime.strptime(s_dt, '%Y-%m-%d')-timedelta(days=7)).strftime('%Y-%m-%d')
    le_dt = (datetime.strptime(e_dt, '%Y-%m-%d')-timedelta(days=7)).strftime('%Y-%m-%d')

    summary = run_ga4_report(s_dt, e_dt, [], ["activeUsers", "screenPageViews", "newUsers"])
    sel_uv = int(summary['activeUsers'].iloc[0]) if not summary.empty else 0
    sel_pv = int(summary['screenPageViews'].iloc[0]) if not summary.empty else 0
    sel_new = int(summary['newUsers'].iloc[0]) if not summary.empty else 0
    new_visitor_ratio = round((sel_new / sel_uv * 100), 1) if sel_uv > 0 else 0

    # [ìˆ˜ì • 1] ì¼ë³„ ë‚ ì§œ í¬ë§·
    df_daily = run_ga4_report(s_dt, e_dt, ["date"], ["activeUsers", "screenPageViews"])
    if not df_daily.empty:
        df_daily = df_daily.rename(columns={'date':'ë‚ ì§œ', 'activeUsers':'UV', 'screenPageViews':'PV'})
        df_daily['ë‚ ì§œ'] = pd.to_datetime(df_daily['ë‚ ì§œ'], format='%Y%m%d').dt.strftime('%m-%d')
        df_daily = df_daily.sort_values('ë‚ ì§œ')

    # [ìˆ˜ì • 2] 3ê°œì›” ì¶”ì´ ì—°ë„ ì •ë ¬
    def fetch_week_data(week_label, date_str):
        ws, we = date_str.split(' ~ ')[0].replace('.', '-'), date_str.split(' ~ ')[1].replace('.', '-')
        res = run_ga4_report(ws, we, [], ["activeUsers", "screenPageViews"])
        year_prefix = ws.split('-')[0]
        if not res.empty:
            return {
                'ì£¼ì°¨': f"{year_prefix}ë…„ {week_label}",
                'year_week': int(year_prefix) * 100 + int(re.search(r'\d+', week_label).group()),
                'UV': int(res['activeUsers'][0]), 'PV': int(res['screenPageViews'][0])
            }
        return None

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(fetch_week_data, wl, dstr) for wl, dstr in list(WEEK_MAP.items())[:12]]
        results = [f.result() for f in concurrent.futures.as_completed(futures) if f.result()]
    df_weekly = pd.DataFrame(results).sort_values('year_week') if results else pd.DataFrame()

    df_pages_count = run_ga4_report(s_dt, e_dt, ["pagePath"], ["screenPageViews"], limit=10000)
    active_article_count = df_pages_count[df_pages_count['pagePath'].str.contains(r'article|news|view|story', case=False, na=False)].shape[0] if not df_pages_count.empty else 0

    def map_source(s):
        s = s.lower()
        if 'naver' in s: return 'ë„¤ì´ë²„'
        if 'daum' in s: return 'ë‹¤ìŒ'
        if 'facebook' in s: return 'í˜ì´ìŠ¤ë¶'
        if '(direct)' in s: return 'ì§ì ‘'
        if 'google' in s: return 'êµ¬ê¸€'
        return 'ê¸°íƒ€'

    df_t_raw = run_ga4_report(s_dt, e_dt, ["sessionSource"], ["screenPageViews"])
    df_t_raw['ìœ ì…ê²½ë¡œ'] = df_t_raw['sessionSource'].apply(map_source)
    df_traffic_curr = df_t_raw.groupby('ìœ ì…ê²½ë¡œ')['screenPageViews'].sum().reset_index().rename(columns={'screenPageViews':'ì¡°íšŒìˆ˜'})
    search_pv = df_traffic_curr[df_traffic_curr['ìœ ì…ê²½ë¡œ'].isin(['ë„¤ì´ë²„','êµ¬ê¸€','ë‹¤ìŒ'])]['ì¡°íšŒìˆ˜'].sum()
    search_inflow_ratio = round((search_pv / df_traffic_curr['ì¡°íšŒìˆ˜'].sum() * 100), 1) if not df_traffic_curr.empty else 0
    df_tl_raw = run_ga4_report(ls_dt, le_dt, ["sessionSource"], ["screenPageViews"])
    df_tl_raw['ìœ ì…ê²½ë¡œ'] = df_tl_raw['sessionSource'].apply(map_source)
    df_traffic_last = df_tl_raw.groupby('ìœ ì…ê²½ë¡œ')['screenPageViews'].sum().reset_index().rename(columns={'screenPageViews':'ì¡°íšŒìˆ˜'})

    df_raw_top = run_ga4_report(s_dt, e_dt, ["pageTitle", "pagePath"], ["screenPageViews", "activeUsers", "userEngagementDuration", "bounceRate"], "screenPageViews", limit=100)
    if not df_raw_top.empty:
        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
            scraped_data = list(executor.map(crawl_single_article, df_raw_top['pagePath'].tolist()))
        df_raw_top['ì‘ì„±ì'], df_raw_top['ì¢‹ì•„ìš”'], df_raw_top['ëŒ“ê¸€'], df_raw_top['ì¹´í…Œê³ ë¦¬'], df_raw_top['ì„¸ë¶€ì¹´í…Œê³ ë¦¬'] = zip(*scraped_data)
        df_raw_all = df_raw_top[~df_raw_top.apply(lambda r: any(x in str(r['pageTitle']).lower() or x in str(r['ì‘ì„±ì']).lower() for x in ['cook&chef', 'ì¿¡ì•¤ì…°í”„']), axis=1)].copy()
        df_top10 = df_raw_all.sort_values('screenPageViews', ascending=False).head(10)
        df_top10['ìˆœìœ„'] = range(1, len(df_top10)+1)
        df_top10 = df_top10.rename(columns={'pageTitle': 'ì œëª©', 'pagePath': 'ê²½ë¡œ', 'screenPageViews': 'ì „ì²´ì¡°íšŒìˆ˜', 'activeUsers': 'ì „ì²´ë°©ë¬¸ììˆ˜', 'userEngagementDuration': 'í‰ê· ì²´ë¥˜ì‹œê°„', 'bounceRate': 'ì´íƒˆë¥ '})
        df_top10['ì²´ë¥˜ì‹œê°„_fmt'] = df_top10['í‰ê· ì²´ë¥˜ì‹œê°„'].apply(lambda x: f"{int(x)//60}ë¶„ {int(x)%60}ì´ˆ")
        df_top10['ë°œí–‰ì¼ì‹œ'], df_top10['ì‹ ê·œë°©ë¬¸ìë¹„ìœ¨'] = s_dt, f"{new_visitor_ratio}%"
    else: df_top10, df_raw_all = pd.DataFrame(), pd.DataFrame()

    return (sel_uv, sel_pv, df_daily, df_weekly, df_traffic_curr, df_traffic_last, df_top10, df_raw_all, new_visitor_ratio, search_inflow_ratio, active_article_count)

# ----------------- 6. ë Œë”ë§ í•¨ìˆ˜ (ìˆ˜ì • ë°˜ì˜) -----------------
def render_summary(df_weekly, cur_pv, cur_uv, new_ratio, search_ratio, df_daily, active_article_count):
    st.markdown('<div class="section-header-container first-section"><div class="section-header">1. ì£¼ê°„ ì „ì²´ ì„±ê³¼ ìš”ì•½</div></div>', unsafe_allow_html=True)
    # [ìˆ˜ì • 3] f-string ë‚´ ì‰¼í‘œ ì˜¤ë¥˜ ìˆ˜ì •
    kpis = [
        ("í™œì„± ê¸°ì‚¬ ìˆ˜", f"{active_article_count:,}", "ê±´"), 
        ("ì£¼ê°„ ì „ì²´ ì¡°íšŒìˆ˜(PV)", f"{cur_pv:,}", "ê±´"), 
        ("ì£¼ê°„ ì´ ë°©ë¬¸ììˆ˜(UV)", f"{cur_uv:,}", "ëª…"), 
        ("ë°©ë¬¸ìë‹¹ í˜ì´ì§€ë·°", round(cur_pv/cur_uv, 1) if cur_uv>0 else 0, "ê±´"), 
        ("ì‹ ê·œ ë°©ë¬¸ì ë¹„ìœ¨", f"{new_ratio}%", ""), 
        ("ê²€ìƒ‰ ìœ ì… ë¹„ìœ¨", f"{search_ratio}%", "")
    ]
    cols = st.columns(6)
    for i, (l, v, u) in enumerate(kpis):
        cols[i].markdown(f'<div class="kpi-container"><div class="kpi-label">{l}</div><div class="kpi-value">{v}<span class="kpi-unit">{u}</span></div></div>', unsafe_allow_html=True)
    c1, c2 = st.columns(2)
    with c1:
        st.markdown('<div class="sub-header">ğŸ“Š ì£¼ê°„ ì¼ë³„ ë°©ë¬¸ ì¶”ì´</div>', unsafe_allow_html=True)
        if not df_daily.empty: st.plotly_chart(px.bar(df_daily.melt(id_vars='ë‚ ì§œ'), x='ë‚ ì§œ', y='value', color='variable', barmode='group', color_discrete_map={'UV': COLOR_GREY, 'PV': COLOR_NAVY}), use_container_width=True)
    with c2:
        st.markdown('<div class="sub-header">ğŸ“ˆ ìµœê·¼ 3ë‹¬ ê°„ ì¶”ì´ ë¶„ì„</div>', unsafe_allow_html=True)
        if not df_weekly.empty:
            fig = go.Figure()
            fig.add_trace(go.Bar(x=df_weekly['ì£¼ì°¨'], y=df_weekly['UV'], name='UV', marker_color=COLOR_GREY))
            fig.add_trace(go.Bar(x=df_weekly['ì£¼ì°¨'], y=df_weekly['PV'], name='PV', marker_color=COLOR_NAVY))
            fig.update_layout(barmode='group', plot_bgcolor='white', margin=dict(t=0))
            st.plotly_chart(fig, use_container_width=True)

# ----------------- 7. ë©”ì¸ ì‹¤í–‰ -----------------
if 'print_mode' not in st.session_state: st.session_state['print_mode'] = False
c1, c2 = st.columns([2, 1])
with c1: st.markdown('<div class="report-title">ğŸ“° ì¿¡ì•¤ì…°í”„ ì£¼ê°„ ì„±ê³¼ë³´ê³ ì„œ</div>', unsafe_allow_html=True)
with c2:
    cb1, cb2 = st.columns(2)
    if st.session_state['print_mode']:
        if cb1.button("ğŸ”™ ëŒ€ì‹œë³´ë“œë¡œ ë³µê·€"): st.session_state['print_mode'] = False; st.rerun()
        if cb2.button("ğŸ–¨ï¸ ì¸ì‡„ ì‹¤í–‰", type="primary"): st.components.v1.html("<script>window.parent.print();</script>", height=0)
    else:
        if cb2.button("ğŸ–¨ï¸ ì¸ì‡„ ë¯¸ë¦¬ë³´ê¸°", type="primary"): st.session_state['print_mode'] = True; st.rerun()
    selected_week = st.selectbox("ğŸ“… ì¡°íšŒ ì£¼ì°¨", list(WEEK_MAP.keys()), key="week_select", label_visibility="collapsed")

uv, pv, df_daily, df_weekly, df_t_c, df_t_l, df_t10, df_r_a, new_r, src_r, act_c = load_all_dashboard_data(selected_week)

st.markdown(f'<div class="period-info">ğŸ“… ì¡°íšŒ ê¸°ê°„: {WEEK_MAP[selected_week]}</div>', unsafe_allow_html=True)
st.markdown(f"<div class='update-time'>ìµœì¢… ì§‘ê³„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>", unsafe_allow_html=True)

if not st.session_state['print_mode']:
    tabs = st.tabs(["1.ì„±ê³¼ìš”ì•½", "2.ì ‘ê·¼ê²½ë¡œ"])
    with tabs[0]: render_summary(df_weekly, pv, uv, new_r, src_r, df_daily, act_c)
else:
    st.markdown('<div class="print-preview-layout">', unsafe_allow_html=True)
    render_summary(df_weekly, pv, uv, new_r, src_r, df_daily, act_c)
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown('<div class="footer-note">â€» ì¿¡ì•¤ì…°í”„(Cook&Chef) ì£¼ê°„ ë°ì´í„° ìë™ ì§‘ê³„ ì‹œìŠ¤í…œ</div>', unsafe_allow_html=True)